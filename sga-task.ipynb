{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User routes on the site\n",
    "## Description\n",
    "**Clickstream** is a sequence of user actions on a website. It allows you to understand how users interact with the site. In this task, you need to find the most frequent custom routes.\n",
    "\n",
    "## Input data\n",
    "Input data is а table with clickstream data in file `hdfs:/data/clickstream.csv`.\n",
    "\n",
    "### Table structure\n",
    "* `user_id (int)` - Unique user identifier.\n",
    "* `session_id (int)` - Unique identifier for the user session. The user's session lasts until the identifier changes.\n",
    "* `event_type (string)` - Event type from the list:\n",
    "    * **page** - visit to the page\n",
    "    * **event** - any action on the page\n",
    "    * <b>&lt;custom&gt;</b> - string with any other type\n",
    "* `event_type (string)` - Page on the site.\n",
    "* `timestamp (int)` - Unix-timestamp of action.\n",
    "\n",
    "### Browser errors\n",
    "Errors can sometimes occur in the user's browser - after such an error appears, we can no longer trust the data of this session and all the following lines after the error or at the same time with it are considered corrupted and **should not be counted** in statistics.\n",
    "\n",
    "When an error occurs on the page, a random string containing the word **error** will be written to the `event_type` field.\n",
    "\n",
    "### Sample of user session\n",
    "<pre>\n",
    "+-------+----------+------------+----------+----------+\n",
    "|user_id|session_id|  event_type|event_page| timestamp|\n",
    "+-------+----------+------------+----------+----------+\n",
    "|    562|       507|        page|      main|1620494781|\n",
    "|    562|       507|       event|      main|1620494788|\n",
    "|    562|       507|       event|      main|1620494798|\n",
    "|    562|       507|        page|    family|1620494820|\n",
    "|    562|       507|       event|    family|1620494828|\n",
    "|    562|       507|        page|      main|1620494848|\n",
    "|    562|       507|wNaxLlerrorU|      main|1620494865|\n",
    "|    562|       507|       event|      main|1620494873|\n",
    "|    562|       507|        page|      news|1620494875|\n",
    "|    562|       507|        page|   tariffs|1620494876|\n",
    "|    562|       507|       event|   tariffs|1620494884|\n",
    "|    562|       514|        page|      main|1620728918|\n",
    "|    562|       514|       event|      main|1620729174|\n",
    "|    562|       514|        page|   archive|1620729674|\n",
    "|    562|       514|        page|     bonus|1620729797|\n",
    "|    562|       514|        page|   tariffs|1620731090|\n",
    "|    562|       514|       event|   tariffs|1620731187|\n",
    "+-------+----------+------------+----------+----------+\n",
    "</pre>\n",
    "\n",
    "#### Correct user routes for a given user:\n",
    "* **Session 507**: main-family-main\n",
    "* **Session 514**: main-archive-bonus-tariffs\n",
    "\n",
    "Route elements are ordered by the time they appear in the clickstream, from earliest to latest.\n",
    "\n",
    "The route must be accounted for completely before the end of the session or an error in the session.\n",
    "\n",
    "## Task\n",
    "You need to use the Spark SQL, Spark RDD and Spark DF interfaces to create a solution file, the lines of which contain **the 30 most frequent user routes** on the site.\n",
    "\n",
    "Each line of the file should contain the `route` and `count` values **separated by tabs**, where:\n",
    "* `route` - route on the site, consisting of pages separated by \"-\".\n",
    "* `count` - the number of user sessions in which this route was.\n",
    "\n",
    "The lines must be **ordered in descending order** of the `count` field.\n",
    "\n",
    "## Criteria\n",
    "You can get maximum of 3.5 points (final grade) for this assignment, depedning on the number of interface you manage to leverage. The criteria are as follows:\n",
    "\n",
    "* 0.5 points – Spark SQL solution with 1 query\n",
    "* 0.5 points – Spark SQL solution with <=2 queries\n",
    "* 0.5 points – Spark RDD solution\n",
    "* 0.5 points – Spark DF solution\n",
    "* 0.5 points – your solution algorithm is relatively optimized, i.e.: no O^2 or O^3 complexities; appropriate object usage; no data leaks etc. This is evaluated by staff.\n",
    "* 1 point – 1 on 1 screening session. During this session staff member can ask you questions regarding your solution logic, framework usage, questionable parts of your code etc. If your code is clean enough, the staff member can just ask you to solve a theoretical problem connected to Spark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup   32241574 2023-09-24 20:38 /data/clickstream.csv\n",
      "drwxr-xr-x   - root supergroup          0 2023-09-24 20:38 /data/transactions\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\tsession_id\tevent_type\tevent_page\ttimestamp\n",
      "562\t507\tpage\tmain\t1695584127\n",
      "562\t507\tevent\tmain\t1695584134\n",
      "562\t507\tevent\tmain\t1695584144\n",
      "562\t507\tevent\tmain\t1695584147\n",
      "562\t507\twNaxLlerrorU\tmain\t1695584154\n",
      "562\t507\tevent\tmain\t1695584154\n",
      "562\t507\tevent\tmain\t1695584154\n",
      "562\t507\tevent\tmain\t1695584160\n",
      "562\t507\tpage\trabota\t1695584166\n",
      "562\t507\tevent\trabota\t1695584174\n",
      "562\t507\tevent\trabota\t1695584181\n",
      "562\t507\tevent\trabota\t1695584189\n",
      "562\t507\tpage\tmain\t1695584194\n",
      "562\t507\tevent\tmain\t1695584204\n",
      "562\t507\tevent\tmain\t1695584211\n",
      "562\t507\tevent\tmain\t1695584211\n",
      "562\t507\tevent\tmain\t1695584219\n",
      "562\t507\tpage\tbonus\t1695584221\n",
      "562\t507\tpage\tonline\t1695584222\n",
      "562\t507\tevent\tonline\t1695584230\n",
      "3539\t849\tpage\tmain\t1695584238\n",
      "3539\t849\tevent\tmain\t1695584252\n",
      "3539\t849\tpage\tonline\t1695584261\n",
      "3539\t849\tpage\tbonus\t1695584269\n",
      "3539\t849\tevent\tbonus\t1695584278\n",
      "3539\t849\tpage\tnews\t1695584285\n",
      "3539\t849\tpage\tmain\t1695584291\n",
      "3539\t849\tevent\tmain\t1695584301\n",
      "3539\t849\tpage\tnews\t1695584306\n",
      "3539\t849\tevent\tnews\t1695584307\n",
      "3539\t849\tpage\tvklad\t1695584317\n",
      "3539\t849\tpage\trabot"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -head /data/clickstream.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to print results in the file and on the screen\n",
    "\n",
    "def print_result(name, result):\n",
    "    file = open(f'{name}_approach.txt', 'w')\n",
    "    for path, count in result[:-1]:\n",
    "        file.write(f\"{path}\\t{str(count)}\\n\")\n",
    "        print(f\"{path}\\t{str(count)}\")\n",
    "    path, count = result[-1]\n",
    "    file.write(f\"{path}\\t{str(count)}\")\n",
    "    file.close()\n",
    "    print(f\"{path}\\t{str(count)}\")\n",
    "    return 'Done!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In feature `event_type` there are 3 main types: event, page and errors of different kinds. `event_type` == 'event' is redundant for our task, thus, for analysis we will take into account only rows where `event_type` is 'page' or contains word 'error'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "# 1. `PANDAS` approach: *This is for reference only!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_page</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>page</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>event</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>event</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>event</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>wNaxLlerrorU</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  session_id    event_type event_page   timestamp\n",
       "0      562         507          page       main  1695584127\n",
       "1      562         507         event       main  1695584134\n",
       "2      562         507         event       main  1695584144\n",
       "3      562         507         event       main  1695584147\n",
       "4      562         507  wNaxLlerrorU       main  1695584154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000000, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('clickstream.csv', sep='\\t')\n",
    "display(df.head())\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us drop out rows where `event_type` == 'event'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_page</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>page</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>wNaxLlerrorU</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>page</td>\n",
       "      <td>rabota</td>\n",
       "      <td>1695584166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  session_id    event_type event_page   timestamp\n",
       "0      562         507          page       main  1695584127\n",
       "4      562         507  wNaxLlerrorU       main  1695584154\n",
       "8      562         507          page     rabota  1695584166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(421610, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df[df['event_type'] != 'event']\n",
    "display(df.head(3))\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_page</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>page</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>wNaxLlerrorU</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>page</td>\n",
       "      <td>rabota</td>\n",
       "      <td>1695584166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  session_id    event_type event_page   timestamp  error\n",
       "0      562         507          page       main  1695584127      0\n",
       "4      562         507  wNaxLlerrorU       main  1695584154      1\n",
       "8      562         507          page     rabota  1695584166      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(421610, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['error'] = 0\n",
    "df['error'].where(df['event_type'] == 'page', 1, inplace=True)\n",
    "display(df.head(3))\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>error_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>1695584154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4567</td>\n",
       "      <td>514</td>\n",
       "      <td>1695584351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>461</td>\n",
       "      <td>174</td>\n",
       "      <td>1695584529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  session_id  error_timestamp\n",
       "4       562         507       1695584154\n",
       "39     4567         514       1695584351\n",
       "70      461         174       1695584529"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(20899, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_table = df[['user_id', 'session_id', 'timestamp']][df['error'] == 1]\n",
    "error_table.rename(columns={'timestamp': 'error_timestamp'}, inplace=True)\n",
    "display(error_table.head(3))\n",
    "display(error_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With duplicates\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>error_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4567</td>\n",
       "      <td>514</td>\n",
       "      <td>1695584351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>4567</td>\n",
       "      <td>514</td>\n",
       "      <td>1695586124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>4567</td>\n",
       "      <td>514</td>\n",
       "      <td>1695588205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  session_id  error_timestamp\n",
       "39      4567         514       1695584351\n",
       "379     4567         514       1695586124\n",
       "774     4567         514       1695588205"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('With duplicates')\n",
    "error_table[(error_table['user_id'] == 4567) & (error_table['session_id'] == 514)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By dropping duplicates we will get the first error in a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>error_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>1695584154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4567</td>\n",
       "      <td>514</td>\n",
       "      <td>1695584351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>461</td>\n",
       "      <td>174</td>\n",
       "      <td>1695584529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  session_id  error_timestamp\n",
       "4       562         507       1695584154\n",
       "39     4567         514       1695584351\n",
       "70      461         174       1695584529"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without duplicates\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>error_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4567</td>\n",
       "      <td>514</td>\n",
       "      <td>1695584351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  session_id  error_timestamp\n",
       "39     4567         514       1695584351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_table1 = error_table.drop_duplicates(subset=['user_id', 'session_id'], keep='first')\n",
    "display(error_table1.head(3))\n",
    "print('Without duplicates')\n",
    "error_table1[(error_table1['user_id'] == 4567) & (error_table1['session_id'] == 514)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_page</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>error</th>\n",
       "      <th>error_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>page</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584127</td>\n",
       "      <td>0</td>\n",
       "      <td>1.695584e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>wNaxLlerrorU</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584154</td>\n",
       "      <td>1</td>\n",
       "      <td>1.695584e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>page</td>\n",
       "      <td>rabota</td>\n",
       "      <td>1695584166</td>\n",
       "      <td>0</td>\n",
       "      <td>1.695584e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  session_id    event_type event_page   timestamp  error  \\\n",
       "0      562         507          page       main  1695584127      0   \n",
       "1      562         507  wNaxLlerrorU       main  1695584154      1   \n",
       "2      562         507          page     rabota  1695584166      0   \n",
       "\n",
       "   error_timestamp  \n",
       "0     1.695584e+09  \n",
       "1     1.695584e+09  \n",
       "2     1.695584e+09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(421610, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pd.merge(df, error_table1, how='left', on=['user_id','session_id'])\n",
    "display(result.head(3))\n",
    "display(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_page</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>error</th>\n",
       "      <th>error_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562</td>\n",
       "      <td>507</td>\n",
       "      <td>page</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584127</td>\n",
       "      <td>0</td>\n",
       "      <td>1.695584e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3539</td>\n",
       "      <td>849</td>\n",
       "      <td>page</td>\n",
       "      <td>main</td>\n",
       "      <td>1695584238</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3539</td>\n",
       "      <td>849</td>\n",
       "      <td>page</td>\n",
       "      <td>online</td>\n",
       "      <td>1695584261</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  session_id event_type event_page   timestamp  error  \\\n",
       "0      562         507       page       main  1695584127      0   \n",
       "6     3539         849       page       main  1695584238      0   \n",
       "7     3539         849       page     online  1695584261      0   \n",
       "\n",
       "   error_timestamp  \n",
       "0     1.695584e+09  \n",
       "6              NaN  \n",
       "7              NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.drop(result[(result['error_timestamp'] - result['timestamp'] <= 0)].index)\n",
    "result.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294335, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "routes = result.groupby(['user_id', 'session_id'])[['event_page']].agg(lambda x: x)['event_page'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(int)\n",
    "for route in routes:\n",
    "    if not isinstance(route, str):\n",
    "        route = '-'.join(route)\n",
    "    d[route] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = sorted(d.items(), key=lambda x: x[1], reverse=True)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main\t8090\n",
      "main-archive\t1096\n",
      "main-rabota\t1039\n",
      "main-internet\t880\n",
      "main-bonus\t865\n",
      "main-news\t760\n",
      "main-tariffs\t669\n",
      "main-online\t584\n",
      "main-vklad\t514\n",
      "main-rabota-archive\t167\n",
      "main-archive-rabota\t167\n",
      "main-bonus-archive\t139\n",
      "main-rabota-bonus\t137\n",
      "main-news-rabota\t134\n",
      "main-bonus-rabota\t133\n",
      "main-archive-internet\t131\n",
      "main-rabota-news\t129\n",
      "main-internet-rabota\t128\n",
      "main-archive-news\t125\n",
      "main-internet-archive\t123\n",
      "main-rabota-internet\t123\n",
      "main-archive-bonus\t117\n",
      "main-tariffs-internet\t114\n",
      "main-internet-bonus\t114\n",
      "main-news-archive\t112\n",
      "main-news-internet\t108\n",
      "main-archive-tariffs\t103\n",
      "main-tariffs-archive\t102\n",
      "main-internet-news\t102\n",
      "main-main\t94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_result('REF1_pure_pandas', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Brute force `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pandas_approach(row):\n",
    "    \n",
    "    user = row['user_id']\n",
    "    session = row['session_id']\n",
    "    event_type = row['event_type']\n",
    "    event_page = row['event_page']\n",
    "    time = row['timestamp']\n",
    "    \n",
    "    if user not in user_session:\n",
    "        user_session[user] = {'stop_list': []}\n",
    "    if session not in user_session[user]:\n",
    "        user_session[user][session] = {'path': [],\n",
    "                                       'time': []}                                       \n",
    "    \n",
    "    if session not in user_session[user]['stop_list']:\n",
    "        if event_type in ['page', 'event']:\n",
    "            if event_type == 'page':                \n",
    "                user_session[user][session]['path'].append(event_page)\n",
    "                user_session[user][session]['time'].append(time)\n",
    "        else:\n",
    "            user_session[user]['stop_list'].append(session)\n",
    "            if time == user_session[user][session]['time'][-1]:\n",
    "                user_session[user][session]['path'] = user_session[user][session]['path'][:-1] \n",
    "                \n",
    "    return 'Done!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_session = {}\n",
    "df.apply(pandas_approach, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = [\"-\".join(session['path']) for user in user_session.values() for session in user.values() if not isinstance(session, list)]\n",
    "result = sorted(Counter(paths).items(), key=lambda x: (x[1], list(x[0])), reverse=True)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main\t8090\n",
      "main-archive\t1096\n",
      "main-rabota\t1039\n",
      "main-internet\t880\n",
      "main-bonus\t865\n",
      "main-news\t760\n",
      "main-tariffs\t669\n",
      "main-online\t584\n",
      "main-vklad\t514\n",
      "main-rabota-archive\t167\n",
      "main-archive-rabota\t167\n",
      "main-bonus-archive\t139\n",
      "main-rabota-bonus\t137\n",
      "main-news-rabota\t134\n",
      "main-bonus-rabota\t133\n",
      "main-archive-internet\t131\n",
      "main-rabota-news\t129\n",
      "main-internet-rabota\t128\n",
      "main-archive-news\t125\n",
      "main-rabota-internet\t123\n",
      "main-internet-archive\t123\n",
      "main-archive-bonus\t117\n",
      "main-tariffs-internet\t114\n",
      "main-internet-bonus\t114\n",
      "main-news-archive\t112\n",
      "main-news-internet\t108\n",
      "main-archive-tariffs\t103\n",
      "main-tariffs-archive\t102\n",
      "main-internet-news\t102\n",
      "main-main\t94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_result('REF2_dict', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# 2. `Spark SQL` approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spark SQL in ONE query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2023-10-10 16:42:02,712 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName='jupyter')\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "se = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------+----------+----------+\n",
      "|user_id|session_id|  event_type|event_page| timestamp|\n",
      "+-------+----------+------------+----------+----------+\n",
      "|    562|       507|        page|      main|1695584127|\n",
      "|    562|       507|       event|      main|1695584134|\n",
      "|    562|       507|       event|      main|1695584144|\n",
      "|    562|       507|       event|      main|1695584147|\n",
      "|    562|       507|wNaxLlerrorU|      main|1695584154|\n",
      "+-------+----------+------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path = '/data/clickstream.csv'\n",
    "\n",
    "df = se.read.options(delimiter=\"\\t\", header=True).csv(path)\n",
    "df.registerTempTable(\"df\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = se.sql( \\\n",
    "'''\n",
    " SELECT route, COUNT(route) as count\n",
    "    FROM (\n",
    "    SELECT concat_ws('-', (collect_list(struct(joined_sql.timestamp, joined_sql.event_page))).event_page) as route, joined_sql.user_id, joined_sql.session_id\n",
    "        FROM (\n",
    "            SELECT *\n",
    "                FROM (\n",
    "                    SELECT INT(user_id), INT(session_id), event_type, event_page, INT(timestamp)\n",
    "                        FROM df\n",
    "                        WHERE df.event_type != 'event'\n",
    "                        order by user_id, session_id, timestamp) as spark_sql\n",
    "                LEFT JOIN (\n",
    "                            SELECT err_table.err_user_id, err_table.err_session_id, min(err_table.error_timestamp) as error_timestamp\n",
    "                                FROM (\n",
    "                                SELECT user_id as err_user_id, session_id as err_session_id, timestamp as error_timestamp\n",
    "                                    FROM (\n",
    "                                    SELECT INT(user_id), INT(session_id), event_type, event_page, INT(timestamp), INT(event_type like '%error%') as error\n",
    "                                FROM df\n",
    "                                WHERE df.event_type != 'event'\n",
    "                                order by user_id, session_id, timestamp\n",
    "                                    ) as spark_sql\n",
    "                                    WHERE error == 1\n",
    "                                    order by user_id, session_id, error_timestamp) as err_table\n",
    "                                GROUP BY err_table.err_user_id, err_table.err_session_id\n",
    "                           ) as error_table\n",
    "                 ON spark_sql.user_id == error_table.err_user_id and \n",
    "                   spark_sql.session_id == error_table.err_session_id\n",
    "                WHERE spark_sql.timestamp < error_table.error_timestamp or isnull(error_timestamp)\n",
    "                ORDER BY user_id, session_id, timestamp) as joined_sql\n",
    "        GROUP BY joined_sql.user_id, joined_sql.session_id\n",
    "        ORDER BY joined_sql.user_id, joined_sql.session_id) as final\n",
    "    GROUP BY route\n",
    "    ORDER BY count desc        \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main\t8090\n",
      "main-archive\t1096\n",
      "main-rabota\t1039\n",
      "main-internet\t880\n",
      "main-bonus\t865\n",
      "main-news\t760\n",
      "main-tariffs\t669\n",
      "main-online\t584\n",
      "main-vklad\t514\n",
      "main-archive-rabota\t167\n",
      "main-rabota-archive\t167\n",
      "main-bonus-archive\t139\n",
      "main-rabota-bonus\t137\n",
      "main-news-rabota\t134\n",
      "main-bonus-rabota\t133\n",
      "main-archive-internet\t131\n",
      "main-rabota-news\t129\n",
      "main-internet-rabota\t128\n",
      "main-archive-news\t125\n",
      "main-rabota-internet\t123\n",
      "main-internet-archive\t123\n",
      "main-archive-bonus\t117\n",
      "main-tariffs-internet\t114\n",
      "main-internet-bonus\t114\n",
      "main-news-archive\t112\n",
      "main-news-internet\t108\n",
      "main-archive-tariffs\t103\n",
      "main-internet-news\t102\n",
      "main-tariffs-archive\t102\n",
      "main-main\t94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done!'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_result('spark_sql', result.collect()[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DRAFTS for SPARK SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let us drop out rows where `event_type` == 'event'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o41.showString.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)\n\nThe currently active SparkContext was created at:\n\n(No active SparkContext.)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1522)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:102)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:131)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:122)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:177)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:426)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:504)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:526)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:454)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:453)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:497)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:237)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:750)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:204)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2728)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2935)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:326)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m spark_sql \u001b[38;5;241m=\u001b[39m se\u001b[38;5;241m.\u001b[39msql( \\\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mSELECT INT(user_id), INT(session_id), event_type, event_page, INT(timestamp), INT(event_type like '%error%') as error\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m spark_sql\u001b[38;5;241m.\u001b[39mregisterTempTable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark_sql\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mspark_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m spark_sql\u001b[38;5;241m.\u001b[39mcount()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:494\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a bool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o41.showString.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\nsun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\nsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.lang.reflect.Constructor.newInstance(Constructor.java:423)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.lang.Thread.run(Thread.java:750)\n\nThe currently active SparkContext was created at:\n\n(No active SparkContext.)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1522)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:102)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:131)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:122)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:177)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:426)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:504)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:526)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:454)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:453)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:497)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:237)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:750)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:185)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:223)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:220)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:181)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:204)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2728)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2728)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2935)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:287)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:326)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "spark_sql = se.sql( \\\n",
    "'''\n",
    "SELECT INT(user_id), INT(session_id), event_type, event_page, INT(timestamp), INT(event_type like '%error%') as error\n",
    "    FROM df\n",
    "    WHERE df.event_type != 'event'\n",
    "    order by user_id, session_id, timestamp\n",
    "    \n",
    "''')\n",
    "spark_sql.registerTempTable('spark_sql')\n",
    "spark_sql.show(25)\n",
    "spark_sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_table = se.sql( \\\n",
    "'''\n",
    "SELECT err_table.err_user_id, err_table.err_session_id, \n",
    "    min(err_table.error_timestamp) as error_timestamp\n",
    "    FROM (\n",
    "    SELECT user_id as err_user_id, session_id as err_session_id, timestamp as error_timestamp\n",
    "        FROM (\n",
    "        SELECT INT(user_id), INT(session_id), event_type, event_page, INT(timestamp), INT(event_type like '%error%') as error\n",
    "    FROM df\n",
    "    WHERE df.event_type != 'event'\n",
    "    order by user_id, session_id, timestamp\n",
    "        ) as spark_sql\n",
    "        WHERE error == 1\n",
    "        order by user_id, session_id, error_timestamp) as err_table\n",
    "    GROUP BY err_table.err_user_id, err_table.err_session_id\n",
    "    \n",
    "       \n",
    "''')\n",
    "error_table.registerTempTable('error_table')\n",
    "error_table.show(15)\n",
    "error_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_sql = se.sql( \\\n",
    "'''\n",
    "                SELECT *\n",
    "                    FROM spark_sql\n",
    "                    LEFT JOIN error_table on spark_sql.user_id == error_table.err_user_id and \n",
    "                                        spark_sql.session_id == error_table.err_session_id\n",
    "                    where timestamp < error_timestamp or isnull(error_timestamp)\n",
    "                    order by user_id, session_id, timestamp\n",
    "                     \n",
    "    \n",
    "''')\n",
    "joined_sql.registerTempTable('joined_sql')\n",
    "joined_sql.show(15)\n",
    "joined_sql.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that there is no errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_sql.select(['error']).distinct().rdd.map(lambda x: x.error).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result1 = se.sql( \\\n",
    "'''\n",
    "    SELECT concat_ws('-', (collect_list(struct(Timestamp, event_page))).event_page) as route, user_id, session_id\n",
    "    FROM joined_sql\n",
    "    GROUP BY user_id, session_id\n",
    "    order by user_id, session_id\n",
    "''')\n",
    "result1.registerTempTable('result1')\n",
    "result1.show(50)\n",
    "result1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_result = se.sql( \\\n",
    "    '''\n",
    "    SELECT route, COUNT(route) as count\n",
    "        FROM result1\n",
    "        GROUP BY route\n",
    "        order by count desc\n",
    "'''\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_result.show(30)\n",
    "final_result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# 3. `Spark RDD` approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 16:43:10,803 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName='jupyter')\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "se = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------+----------+----------+\n",
      "|user_id|session_id|  event_type|event_page| timestamp|\n",
      "+-------+----------+------------+----------+----------+\n",
      "|    562|       507|        page|      main|1695584127|\n",
      "|    562|       507|       event|      main|1695584134|\n",
      "|    562|       507|       event|      main|1695584144|\n",
      "|    562|       507|       event|      main|1695584147|\n",
      "|    562|       507|wNaxLlerrorU|      main|1695584154|\n",
      "+-------+----------+------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = '/data/clickstream.csv'\n",
    "\n",
    "df = se.read.options(delimiter=\"\\t\", header=True).csv(path)\n",
    "df.registerTempTable(\"df\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(user_id='562', session_id='507', event_type='page', event_page='main', timestamp='1695584127'),\n",
       " Row(user_id='562', session_id='507', event_type='event', event_page='main', timestamp='1695584134'),\n",
       " Row(user_id='562', session_id='507', event_type='event', event_page='main', timestamp='1695584144')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_df = df.rdd\n",
    "rdd_df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id='562', session_id='507', event_type='page', event_page='main', timestamp='1695584127'),\n",
       " Row(user_id='562', session_id='507', event_type='wNaxLlerrorU', event_page='main', timestamp='1695584154'),\n",
       " Row(user_id='562', session_id='507', event_type='page', event_page='rabota', timestamp='1695584166')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_df_filtered = rdd_df.filter(lambda x: 'event' not in x[2])\n",
    "rdd_df_filtered.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tick_error(row):\n",
    "    if 'error' in row['event_type']:\n",
    "        return (row['user_id'], row['session_id']), (row['event_page'], row['timestamp']), 1 \n",
    "    return (row['user_id'], row['session_id']), (row['event_page'], row['timestamp']), 0         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdd_df_err = rdd_df_filtered.map(tick_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('562', '507'), ('main', '1695584127'), 0),\n",
       " (('562', '507'), ('main', '1695584154'), 1),\n",
       " (('562', '507'), ('rabota', '1695584166'), 0),\n",
       " (('562', '507'), ('main', '1695584194'), 0),\n",
       " (('562', '507'), ('bonus', '1695584221'), 0)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_df_err.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_error_table(row):\n",
    "    if row[2] == 1:\n",
    "        return row[0], row[1][1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def first_error(row):\n",
    "    return min(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "err_table = rdd_df_err.map(get_error_table).filter(lambda x: x is not None).groupBy(lambda x: x[0]).map(first_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('3940', '740'), '1696271012'),\n",
       " (('3434', '641'), '1696271432'),\n",
       " (('2092', '521'), '1696274764')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_table.collect()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rdd_df_joined = rdd_df_err.leftOuterJoin(err_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('2569', '54'), (('online', '1696270680'), '1696285133')),\n",
       " (('2569', '54'), (('bonus', '1696272716'), '1696285133')),\n",
       " (('2569', '54'), (('online', '1696274201'), '1696285133')),\n",
       " (('2569', '54'), (('bonus', '1696274460'), '1696285133')),\n",
       " (('2569', '54'), (('main', '1696275080'), '1696285133'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_df_joined.collect()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1696270680 1696285133 True\n"
     ]
    }
   ],
   "source": [
    "# test filtration\n",
    "x = (('2569', '54'), (('online', '1696270680'), '1696285133'))\n",
    "print(int(x[1][0][1]), int(x[1][1]), int(x[1][0][1]) < int(x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "routes = rdd_df_joined.filter(lambda x: (x[1][1] is None or int(x[1][0][1]) < int(x[1][1]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('2569', '54'), (('online', '1696270680'), '1696285133')),\n",
       " (('2569', '54'), (('bonus', '1696272716'), '1696285133')),\n",
       " (('2569', '54'), (('online', '1696274201'), '1696285133'))]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes.collect()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def route(row):   \n",
    "    return [e for e in row[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = routes.groupBy(lambda x: x[0]).map(route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "routes = []\n",
    "for line in result.collect():\n",
    "    paths = []\n",
    "    for path in line:\n",
    "        paths.append(path[1][0][0])\n",
    "    routes.append(\"-\".join(paths))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "answer = sorted(Counter(routes).items(), key=lambda x: x[1], reverse=True)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main\t8090\n",
      "main-archive\t1089\n",
      "main-rabota\t1038\n",
      "main-internet\t879\n",
      "main-bonus\t865\n",
      "main-news\t759\n",
      "main-tariffs\t668\n",
      "main-online\t584\n",
      "main-vklad\t513\n",
      "main-rabota-archive\t167\n",
      "main-archive-rabota\t167\n",
      "main-bonus-archive\t139\n",
      "main-rabota-bonus\t137\n",
      "main-news-rabota\t134\n",
      "main-bonus-rabota\t133\n",
      "main-archive-internet\t131\n",
      "main-rabota-news\t129\n",
      "main-internet-rabota\t128\n",
      "main-archive-news\t125\n",
      "main-rabota-internet\t123\n",
      "main-internet-archive\t123\n",
      "main-archive-bonus\t117\n",
      "main-tariffs-internet\t114\n",
      "main-internet-bonus\t114\n",
      "main-news-archive\t112\n",
      "main-news-internet\t108\n",
      "main-archive-tariffs\t103\n",
      "main-internet-news\t102\n",
      "main-tariffs-archive\t102\n",
      "main-main\t94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done!'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_result('spark_rdd', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# 4. `Spark DataFrame` approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 16:43:47,752 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# connect, context, session\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName='jupyter')\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "se = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/data/clickstream.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------+----------+----------+\n",
      "|user_id|session_id|  event_type|event_page| timestamp|\n",
      "+-------+----------+------------+----------+----------+\n",
      "|    562|       507|        page|      main|1695584127|\n",
      "|    562|       507|       event|      main|1695584134|\n",
      "|    562|       507|       event|      main|1695584144|\n",
      "|    562|       507|       event|      main|1695584147|\n",
      "|    562|       507|wNaxLlerrorU|      main|1695584154|\n",
      "+-------+----------+------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_df = se.read.options(delimiter=\"\\t\", header=True).csv(path)\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df =  spark_df[spark_df['event_type'] != 'event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "421610"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+----------+-----+\n",
      "|user_id|session_id|event_page| timestamp|error|\n",
      "+-------+----------+----------+----------+-----+\n",
      "|    562|       507|      main|1695584127|    0|\n",
      "|    562|       507|      main|1695584154|    1|\n",
      "|    562|       507|    rabota|1695584166|    0|\n",
      "|    562|       507|      main|1695584194|    0|\n",
      "|    562|       507|     bonus|1695584221|    0|\n",
      "|    562|       507|    online|1695584222|    0|\n",
      "|   3539|       849|      main|1695584238|    0|\n",
      "|   3539|       849|    online|1695584261|    0|\n",
      "|   3539|       849|     bonus|1695584269|    0|\n",
      "|   3539|       849|      news|1695584285|    0|\n",
      "|   3539|       849|      main|1695584291|    0|\n",
      "|   3539|       849|      news|1695584306|    0|\n",
      "|   3539|       849|     vklad|1695584317|    0|\n",
      "|   3539|       849|    rabota|1695584319|    0|\n",
      "|   3539|       849|     bonus|1695584324|    0|\n",
      "|    461|       174|      main|1695584343|    0|\n",
      "|   4567|       514|      main|1695584345|    0|\n",
      "|   4567|       514|      main|1695584351|    1|\n",
      "|   4567|       514|   archive|1695584373|    0|\n",
      "|   4567|       514|  internet|1695584381|    0|\n",
      "+-------+----------+----------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark_df.withColumn('error', spark_df.event_type.like(\"%error%\").cast('Integer'))\n",
    "spark_df = spark_df.drop('event_type')\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------------+\n",
      "|user_id|session_id|error_timestamp|\n",
      "+-------+----------+---------------+\n",
      "|    562|       507|     1695584154|\n",
      "|   4567|       514|     1695584351|\n",
      "|    461|       174|     1695584529|\n",
      "|    844|       258|     1695584652|\n",
      "|    461|       174|     1695584698|\n",
      "+-------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20899"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_table = spark_df[['user_id', 'session_id', 'timestamp']][spark_df['error'] == 1]\n",
    "error_table = error_table.withColumnRenamed('timestamp', 'error_timestamp')\n",
    "error_table.show(5)\n",
    "error_table.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us leave only the first error entry in each `user-session` pair.\n",
    "\n",
    "For example, 3 errors occured during the session_id = 514 for user_id = 4567. After dropping the duplicates we will have only the first error occurence left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------------+\n",
      "|user_id|session_id|error_timestamp|\n",
      "+-------+----------+---------------+\n",
      "|   4567|       514|     1695584351|\n",
      "|   4567|       514|     1695586124|\n",
      "|   4567|       514|     1695588205|\n",
      "+-------+----------+---------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20899"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before\n",
    "error_table[(error_table['user_id'] == 4567) & (error_table['session_id'] == 514)].show()\n",
    "error_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------------+\n",
      "|user_id|session_id|error_timestamp|\n",
      "+-------+----------+---------------+\n",
      "|   4567|       514|     1695584351|\n",
      "+-------+----------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14569"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After\n",
    "error_table = error_table.dropDuplicates(['user_id', 'session_id'])\n",
    "error_table[(error_table['user_id'] == 4567) & (error_table['session_id'] == 514)].show()\n",
    "error_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark_df = spark_df.join(error_table, ['user_id', 'session_id'], 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+----------+-----+---------------+\n",
      "|user_id|session_id|event_page| timestamp|error|error_timestamp|\n",
      "+-------+----------+----------+----------+-----+---------------+\n",
      "|    562|       507|      main|1695584127|    0|     1695584154|\n",
      "|    562|       507|      main|1695584154|    1|     1695584154|\n",
      "|    562|       507|    rabota|1695584166|    0|     1695584154|\n",
      "|    562|       507|      main|1695584194|    0|     1695584154|\n",
      "|    562|       507|     bonus|1695584221|    0|     1695584154|\n",
      "|    562|       507|    online|1695584222|    0|     1695584154|\n",
      "|    461|       174|      main|1695584343|    0|     1695584529|\n",
      "|   3539|       849|      main|1695584238|    0|           null|\n",
      "|   3539|       849|    online|1695584261|    0|           null|\n",
      "|   3539|       849|     bonus|1695584269|    0|           null|\n",
      "|   3539|       849|      news|1695584285|    0|           null|\n",
      "|   3539|       849|      main|1695584291|    0|           null|\n",
      "|   3539|       849|      news|1695584306|    0|           null|\n",
      "|   3539|       849|     vklad|1695584317|    0|           null|\n",
      "|   3539|       849|    rabota|1695584319|    0|           null|\n",
      "+-------+----------+----------+----------+-----+---------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "421610"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df.show(15)\n",
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spark_df[(col(\"error_timestamp\").isNull()) | (col(\"timestamp\").cast('Integer')  < col(\"error_timestamp\").cast('Integer'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = result.groupBy(\"user_id\", \"session_id\").agg(collect_list(\"event_page\").alias('path')).groupBy(\"path\").count().orderBy(['count','path'], ascending=False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer = [['-'.join(path[0]), path[1]] for path in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main\t8076\n",
      "main-archive\t1088\n",
      "main-rabota\t1034\n",
      "main-internet\t878\n",
      "main-bonus\t863\n",
      "main-news\t759\n",
      "main-tariffs\t668\n",
      "main-online\t580\n",
      "main-vklad\t513\n",
      "main-rabota-archive\t166\n",
      "main-archive-rabota\t166\n",
      "main-bonus-archive\t139\n",
      "main-rabota-bonus\t136\n",
      "main-news-rabota\t133\n",
      "main-bonus-rabota\t133\n",
      "main-archive-internet\t131\n",
      "main-rabota-news\t129\n",
      "main-internet-rabota\t128\n",
      "main-archive-news\t125\n",
      "main-internet-archive\t123\n",
      "main-rabota-internet\t122\n",
      "main-archive-bonus\t117\n",
      "main-tariffs-internet\t114\n",
      "main-news-archive\t112\n",
      "main-internet-bonus\t112\n",
      "main-news-internet\t108\n",
      "main-internet-news\t102\n",
      "main-archive-tariffs\t102\n",
      "main-tariffs-archive\t101\n",
      "main-main\t94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done!'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_result('spark_df', answer[:30])"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "week-4-spark-homework"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
